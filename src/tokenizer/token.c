
#include "../../include/lexer.h"
/*
üéØ Mi recomendaci√≥n de orden REAL

‚úÖ Termina add_token()
‚úÖ A√±ade t_quote_type a las estructuras
‚úÖ Crea tokenize() b√°sico que solo detecte operadores y palabras SIN comillas
‚úÖ Crea print_tokens() para debug
‚úÖ Prueba con strings simples: "ls | grep hola"
‚úÖ Implementa try_extract_quoted() con backtracking
‚úÖ Integra el manejo de comillas en tokenize()
‚úÖ Prueba casos complejos

*/

tokenize()
{
	mientras no llegues al final del string:
	- saltar espacios
	- si es operador ‚Üí crear token operador
	- si es comilla ‚Üí intentar extraer con backtracking
		- si falla ‚Üí tratar como palabra normal
	- si no ‚Üí extraer palabra normal
}
/**
 * @brief 
 * 
 * @param type 
 * @param value 
 * @return t_token* 
 */
t_token	*createtoken(t_token_type type, char *value)
{
	t_token	*token;

	token = malloc(sizeof(t_token));
	if (!token)
		return (NULL);
	token->type = type;
	token->value = ft_strdup(value);
	token->next = NULL;
	return (token);
}

/**
 * @brief 
 * 
 * @param head 
 * @param new 
 */
void	add_token(t_token **head, t_token *new)
{
	t_token	*tmp;

	if (!*head)
	{
		*head = new;
		return ;
	}
	tmp = *head;
	while (tmp-> next)
		tmp = tmp->next;
	tmp->next = new;
}

/**
 * @brief Construct a new check operator object
 * 
 * @param state 
 */
check_operator(t_lexer_state *state)
{
	char	c;

	c = state->input[state->pos];
	while (c)
	{
		if (c == '|')
		{
			t_token *token = createtoken(TOKEN_PIPE, "|");
			add_token( head, token);
			state->pos++;
		}
		if (c == '<' && state->input[state->pos+1] == '<')
		{
			t_token *token = createtoken(TOKEN_APPEND, "<<");
			add_token( head, token);
			state->pos += 2;
		}
		else
		{
			t_token *token = createtoken(TOKEN_REDIR_IN , "<");
			add_token( head, token);
			state->pos++;
		}
		if (c == '>' && state->input[state->pos+1] == '>')
		{
			t_token *token = createtoken(TOKEN_HEREDOC, ">>");
			add_token( head, token);
			state->pos += 2;
		}
		else
		{
			t_token *token = createtoken(TOKEN_REDIR_OUT, ">");
			add_token( head, token);
			state->pos++;
		}
	}
}

/**
 * @brief Construct a new extract word object
 * 
 * @param state 
 */
extract_word(t_lexer_state *state)
{
Debe:

Leer caracteres mientras no sean espacios ni operadores
Crear un string con esos caracteres
Crear un token TOKEN_WORD con quote = QUOTE_NONE
Avanzar posici√≥n
}

/*
BACKTRACKING üéØ
Concepto clave:
Cuando encuentras una comilla (" o '):

Guardas la posici√≥n actual (checkpoint)
Intentas encontrar la comilla de cierre
Si la encuentras ‚Üí √âxito, creas token con el tipo de comilla
Si NO la encuentras ‚Üí BACKTRACK: vuelves al checkpoint y tratas la comilla como un car√°cter normal

Pregunta para ti: ¬øEntiendes por qu√© esto es backtracking? Es como decir "a ver si funciona, y si no, deshago y pruebo otra cosa".
Funci√≥n: try_extract_quoted(t_lexer_state *state, char quote_char)
Debe retornar:

El string extra√≠do si tuvo √©xito
NULL si fall√≥ (y entonces haces backtrack)

Detalles importantes:

En comillas dobles ", el backslash \ escapa el siguiente car√°cter
En comillas simples ', NO hay escapes, todo es literal
*/

/*
Jerarqu√≠a de comillas
La jerarqu√≠a que quieres:

Comillas dobles tienen prioridad
Comillas simples
Sin comillas

¬øPero qu√© significa esto en la pr√°ctica?
Cuando est√°s dentro de comillas dobles, las simples son literales:
"texto con 'simples'" ‚Üí una sola palabra
Cuando est√°s dentro de comillas simples, las dobles son literales:
'texto con "dobles"' ‚Üí una sola palabra
Pero ojo: la jerarqu√≠a aplica cuando est√°s buscando qu√© comilla abrir. Si encuentras primero ", buscas su cierre ignorando ' intermedias.
Pregunta: ¬øVes la diferencia entre "jerarqu√≠a de apertura" y "anidamiento"? No es lo mismo.
*/